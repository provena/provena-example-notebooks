{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import registry\n",
    "import datastore\n",
    "import mdsisclienttools.auth.TokenManager as ProvenaAuth\n",
    "from utils import pprint_json\n",
    "import json\n",
    "PROVENA_DOMAIN = \"dev.rrap-is.com\"\n",
    "\n",
    "# Edit this to point to the Keycloak instance for your Provena instance\n",
    "kc_endpoint = \"https://auth.dev.rrap-is.com/auth/realms/rrap\"\n",
    "\n",
    "stage = \"DEV\"\n",
    "registry_endpoint = \"https://registry-api.{}\".format(PROVENA_DOMAIN)\n",
    "provenance_endpoint = \"https://prov-api.{}\".format(PROVENA_DOMAIN)\n",
    "data_store_endpoint = \"https://data-api.{}\".format(PROVENA_DOMAIN)\n",
    "job_endpoint =  \"https://job-api.{}\".format(PROVENA_DOMAIN)\n",
    "\n",
    "# sets up auth connections - could potentially open browser window if not signed\n",
    "# in recently - caches in .tokens.json - ensure this is included in gitignore\n",
    "provena_auth = ProvenaAuth.DeviceFlowManager(\n",
    "    stage=stage,\n",
    "    keycloak_endpoint=kc_endpoint\n",
    ")\n",
    "\n",
    "# expose the get auth function which is used for provena methods \n",
    "get_auth = provena_auth.get_auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Dataset Metadata (Adding missed missed, changing existing fields)\n",
    "Updating metadata facilitates the addition of new fields, as well as overwriting existing fields. The process is implemented as a complete override, meaning you will need to provide the update endpoint with a complete reflection of the final desired metadata after the update process. This necessitates the acquisition of the current existing metadata. To this end, the following sections will demonstrate how to retrieve the existing metadata from the source of truth (Data Store), and how to update it, then post this update to the Data Store via the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch Existing Metadata using the registry\n",
    "incase others have edited the metadata of a dataset, its best practise to fetch the metadata from the registry (source of truth), and update it with the new fields. This ensures your update process is not overwriting any changes made by other users in fields that you actually desire to leave unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"10378.1/1764358\"\n",
    "current_metadata = registry.fetch_dataset_metadata(registry_endpoint=registry_endpoint, id=dataset_id, auth=get_auth())\n",
    "pprint_json(current_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_metadata = current_metadata # \"copy\"\n",
    "updated_metadata['dataset_info'][\"description\"] = \"This is an updated description for test purposes!\"\n",
    "updated_metadata['dataset_info']['spatial_info']['resolution'] = 0.0013\n",
    "updated_metadata['associations'][\"point_of_contact\"] = \"Peter Baker\"\n",
    "pprint_json(updated_metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post update to Datastore API\n",
    "Once you have the metadata, you can update it with the new fields, and post it to the Datastore API. The API will then update the metadata in the Datastore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason = \"Testing API update functionality.\"\n",
    "update_response = datastore.update_dataset(datastore_endpoint=data_store_endpoint, updated_metadata=updated_metadata, dataset_id=dataset_id, reason=reason, auth=get_auth())\n",
    "pprint_json(update_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Method to editing the metadata payload for update\n",
    "1. Fetch the current metadata\n",
    "2. Save to file and edit this file\n",
    "3. Read in the file and post to API.\n",
    "\n",
    "This method prevents the need to edit metadata in code which can be confusing with the key-value pairs and correct location. Nevertheless, the API will reject incorrectly formatted metadata payloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_metadata = registry.fetch_dataset_metadata(registry_endpoint=registry_endpoint, id=dataset_id, auth=get_auth())\n",
    "# write to file\n",
    "updated_metadata_file_path = \"configs/updated_metadata.json\"\n",
    "with open(updated_metadata_file_path, \"w\") as f:\n",
    "    json.dump(current_metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After editing the file, read it back in and send to the update endpoint\n",
    "with open(updated_metadata_file_path) as f:\n",
    "    updated_metadata = json.load(f)\n",
    "\n",
    "update_response = datastore.update_dataset(datastore_endpoint=data_store_endpoint, updated_metadata=updated_metadata, dataset_id=dataset_id, reason=reason, auth=get_auth())\n",
    "pprint_json(update_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
